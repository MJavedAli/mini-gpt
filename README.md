# mini-gpt
Reference implementation of a GPT-style decoder-only Transformer built from first principles in PyTorch, demonstrating multi-head self-attention, causal masking, and autoregressive language modeling.
